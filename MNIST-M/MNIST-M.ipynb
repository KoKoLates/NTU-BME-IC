{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33dc5672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jun 11 02:59:14 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 457.49       Driver Version: 457.49       CUDA Version: 11.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 105... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   39C    P8    N/A /  N/A |     78MiB /  4096MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31103f90",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bdae2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import DatasetFolder\n",
    "\n",
    "# For the progress bar.\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "# [Hint]: \"ConcatDataset\" may be possibly useful \n",
    "from torch.utils.data import ConcatDataset, DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e1fd30",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7668e381",
   "metadata": {},
   "outputs": [],
   "source": [
    "your_student_ID = 'b08611035'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09166eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def configuration():\n",
    "    config = {\n",
    "        'batch_size': 2048,                    # Batch size for training, validation, and testing.\n",
    "        'num_classes': 10,                     # number of class\n",
    "        'seed': 1126,                          # random seed\n",
    "        'num_epoch' : 30,                      # number of training epoch\n",
    "        'optimizer': 'Adam',                   # optimization algorithm (optimizer in torch.optim)\n",
    "        'optim_hparas': {                      # hyper-parameters for the optimizer (depends on which optimizer you are using)\n",
    "            'lr': 0.001,                       # learning rate \n",
    "            'weight_decay' : 1e-5,             # weight_decay\n",
    "             # 'momentum': 0.9                 # momentum for SGD\n",
    "        },\n",
    "        'lr_scheduler': 'ReduceLROnPlateau',   # [Hint] learning rate scheduler\n",
    "        'lr_scheduler_paras': {\n",
    "            'patience' : 10,                   # patience for ReduceLROnPlateau\n",
    "            'factor': 0.1,                     # Reduction factor for ReduceLROnPlateau\n",
    "        },\n",
    "        'model_path': 'model.ckpt',            # the path where checkpoint saved\n",
    "        'csv_path': your_student_ID + '_pred.csv',   # csv path\n",
    "        'num_workers': 2}\n",
    "    \n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2e354dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_config(config):\n",
    "    print('[Info] Print config...')\n",
    "    for key, value in config.items():\n",
    "        print('-- {}: {}'.format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0605d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Print config...\n",
      "-- batch_size: 2048\n",
      "-- num_classes: 10\n",
      "-- seed: 1126\n",
      "-- num_epoch: 30\n",
      "-- optimizer: Adam\n",
      "-- optim_hparas: {'lr': 0.001, 'weight_decay': 1e-05}\n",
      "-- lr_scheduler: ReduceLROnPlateau\n",
      "-- lr_scheduler_paras: {'patience': 10, 'factor': 0.1}\n",
      "-- model_path: model.ckpt\n",
      "-- csv_path: b08611035_pred.csv\n",
      "-- num_workers: 2\n"
     ]
    }
   ],
   "source": [
    "# Print the configuration\n",
    "print_config(configuration())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a596d8f8",
   "metadata": {},
   "source": [
    "## MNIST-M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c6b624",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9fa01ad",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d40b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is important to do data augmentation in training.\n",
    "# However, not every augmentation is useful.\n",
    "# Please think about what kind of augmentation is helpful for digit recognition.\n",
    "\n",
    "train_tfm = transforms.Compose([\n",
    "    # Resize the image into a fixed shape (height = width = 32)\n",
    "    transforms.Resize((32, 32)),\n",
    "    # TO DO\n",
    "    # You may add some transforms here.\n",
    "\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5), std=(0.5)),\n",
    "])\n",
    "\n",
    "# You 'may' need to do 'some' proper augmentations in testing and validation.\n",
    "# Or you can simply resize the PIL image and transform it into Tensor.\n",
    "test_tfm = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5), std=(0.5)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ffc678",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d14cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreparation(Dataset):\n",
    "    def __init__(self, data_path=None, label_path=None, transform=None, target_transform=None):\n",
    "        \n",
    "        self.data_path = data_path \n",
    "        self.label_path = label_path \n",
    "        \n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "        ## preprocess files\n",
    "        self.preprocess(self.data_path, self.label_path)\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data_file = self.data_files[idx]\n",
    "        img_path = os.path.join(self.data_path, data_file)\n",
    "        image = Image.open(img_path) # plt.imread(img_path)\n",
    " \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        if self.label_path is None:\n",
    "            return image, -1, data_file\n",
    "        \n",
    "        label = self.file_labels['label'][self.file_labels['image_name'] == data_file].iloc[0]\n",
    "            \n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "\n",
    "        return image, label, data_file\n",
    "    \n",
    "    def preprocess(self, data_path, label_path):\n",
    "        self.data_files = os.listdir(data_path)\n",
    "        self.data_files.sort()\n",
    "  \n",
    "        if label_path is not None:\n",
    "            self.file_labels = pd.read_csv(label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec56e00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    def __init__(self, train_batch_size=128, data_path='./digit/train', label_path='./digit/train.csv', train_tfm=None, test_tfm=None):\n",
    "        \n",
    "        # Training\n",
    "        self.train_dataset = DataPreparation(data_path=data_path,\n",
    "                                            label_path=label_path,\n",
    "                                            transform=train_tfm)\n",
    "        \n",
    "        # Validation\n",
    "        valid_data_path = data_path.replace('train', 'valid')\n",
    "        valid_label_path = label_path\n",
    "        \n",
    "        if label_path is not None:\n",
    "            valid_label_path = label_path.replace('train', 'valid')\n",
    "\n",
    "        self.valid_dataset = DataPreparation(data_path=valid_data_path,\n",
    "                                            label_path=valid_label_path,\n",
    "                                            transform=test_tfm)\n",
    "        \n",
    "        # Testing\n",
    "        test_data_path = data_path.replace('train', 'test')\n",
    "        test_label_path = label_path\n",
    "        \n",
    "        if label_path is not None:\n",
    "            if int(your_student_ID[-1]) % num_link == 1:\n",
    "                test_label_path = label_path.replace('train', 'sample')\n",
    "            else:\n",
    "                test_label_path = label_path.replace('train', 'test')\n",
    "        \n",
    "        self.test_dataset = DataPreparation(data_path=test_data_path,\n",
    "                                            label_path=test_label_path,\n",
    "                                            transform=test_tfm)\n",
    "               \n",
    "        print(len(self.train_dataset))\n",
    "        print(len(self.valid_dataset))\n",
    "        print(len(self.test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d71848",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(train_tfm=train_tfm, test_tfm=test_tfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbbbbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [(data.train_dataset[i * 450][0] + 1) / 2 for i in range(100)]\n",
    "grid_img = torchvision.utils.make_grid(images, nrow = 10)\n",
    "plt.figure(figsize = (10, 10))\n",
    "plt.imshow(grid_img.permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff489426",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [(data.test_dataset[i * 100][0] + 1) / 2 for i in range(100)]\n",
    "grid_img = torchvision.utils.make_grid(images, nrow = 10)\n",
    "plt.figure(figsize = (10, 10))\n",
    "plt.imshow(grid_img.permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f062f937",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19be81a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed\n",
    "def same_seeds(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)  \n",
    "    np.random.seed(seed)  \n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# check device\n",
    "def get_device():\n",
    "    return 'cuda' if torch.cuda.is_available() else 'cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb391036",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bd9cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        # torch.nn.MaxPool2d(kernel_size, stride, padding)\n",
    "        # input dim: [3, 32, 32]\n",
    "        self.cnn_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, 1, 1),    # [64, 32, 32]\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),        # [64, 16, 16]\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, 1, 1),  # [128, 16, 16]\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),        # [128, 8, 8]\n",
    "\n",
    "            nn.Conv2d(128, 256, 3, 1, 1), # [256, 8, 8]\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((4, 4))  # [256, 4, 4]\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(256*4*4, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input (x): [batch_size, 3, 32, 32]\n",
    "        # output: [batch_size, 10]\n",
    "        # Extract features by convolutional layers.\n",
    "        x = self.cnn_layers(x)\n",
    "\n",
    "        # The extracted feature map must be flatten before going to fully-connected layers.\n",
    "        x = x.flatten(1)\n",
    "\n",
    "        # The features are transformed by fully-connected layers to obtain the final logits.\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8200c54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN, self).__init__()\n",
    "        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        # torch.nn.MaxPool2d(kernel_size, stride, padding)\n",
    "        # input dim: [3, 32, 32]\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(3*32*32, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input (x): [batch_size, 3, 32, 32]\n",
    "        # output: [batch_size, 10]\n",
    "        # The extracted feature map must be flatten before going to fully-connected layers.\n",
    "        x = x.flatten(1)\n",
    "\n",
    "        # The features are transformed by fully-connected layers to obtain the final logits.\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8656b817",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47881f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train(config, train_set, valid_set=None, model=None, record=None):\n",
    "    # Fix seeds and device\n",
    "    same_seeds(config['seed'])\n",
    "    device = get_device()\n",
    "    \n",
    "    # Construct data loaders.\n",
    "    train_loader = DataLoader(train_set, batch_size=config['batch_size'], shuffle=True, \n",
    "                              pin_memory=True, num_workers=config['num_workers'])\n",
    "    if valid_set:\n",
    "        valid_loader = DataLoader(valid_set, batch_size=config['batch_size'], shuffle=True, \n",
    "                                  pin_memory=True, num_workers=config['num_workers'])\n",
    "\n",
    "    # Print config\n",
    "    print_config(config)\n",
    "    \n",
    "    # Create model, define a loss function, and optimizer\n",
    "    if not model:\n",
    "        # Initialize a model, and put it on the device specified.\n",
    "        model = CNN().to(device)\n",
    "        # [Hint]: model = getattr(torchvision.models, config['backbone'])().to(device)\n",
    "    \n",
    "    if not record: \n",
    "        record = {\n",
    "            'loss': {'train': [], 'valid': []},      # for recording loss\n",
    "            'acc' : {'train': [], 'valid': []},      # for recording accuracy\n",
    "        }\n",
    "    \n",
    "    # Define loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "    # Initialize optimizer, you may fine-tune some hyperparameters such as learning rate on your own.\n",
    "    optimizer = getattr(torch.optim, config['optimizer'])(model.parameters(), **config['optim_hparas'])\n",
    "\n",
    "    # learning rate scheduler\n",
    "    scheduler = getattr(torch.optim.lr_scheduler, config['lr_scheduler'])(optimizer, **config['lr_scheduler_paras']) \n",
    "    \n",
    "    best_acc = -1.0\n",
    "    lr = config['optim_hparas']['lr']\n",
    "    \n",
    "    # The number of training epochs.\n",
    "    n_epochs = config['num_epoch']\n",
    "    for epoch in range(n_epochs):\n",
    "        # ---------- Training ----------\n",
    "        # Make sure the model is in train mode before training.\n",
    "        model.train()\n",
    "        # These are used to record information in training.\n",
    "        train_loss = []\n",
    "        train_accs = []\n",
    "\n",
    "        # Iterate the training set by batches.\n",
    "        for batch in tqdm(train_loader):\n",
    "            # A batch consists of image data and corresponding labels.\n",
    "            imgs, labels, data_file = batch\n",
    "            # Forward the data. (Make sure data and model are on the same device.)\n",
    "            logits = model(imgs.to(device))\n",
    "            # Calculate the cross-entropy loss.\n",
    "            # We don't need to apply softmax before computing cross-entropy as it is done automatically.\n",
    "            loss = criterion(logits, labels.to(device))\n",
    "            # Gradients stored in the parameters in the previous step should be cleared out first.\n",
    "            optimizer.zero_grad()\n",
    "            # Compute the gradients for parameters.\n",
    "            loss.backward()\n",
    "            # Clip the gradient norms for stable training.\n",
    "            grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n",
    "            # Update the parameters with computed gradients.\n",
    "            optimizer.step()\n",
    "            # Compute the accuracy for current batch.\n",
    "            acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n",
    "            # Record the loss and accuracy.\n",
    "            train_loss.append(loss.item())\n",
    "            train_accs.append(acc.item())\n",
    "\n",
    "        # The average loss and accuracy of the training set is the average of the recorded values.\n",
    "        train_loss = sum(train_loss) / len(train_loss)\n",
    "        train_acc = sum(train_accs) / len(train_accs)\n",
    "\n",
    "        record['loss']['train'].append(train_loss)\n",
    "        record['acc']['train'].append(train_acc)\n",
    "        \n",
    "        # Print the information.\n",
    "        print(f\"[ Train | {epoch + 1:04d}/{n_epochs:04d} ] loss = {train_loss:.6f}, acc = {train_acc:.6f}\")\n",
    "        \n",
    "        if valid_set:\n",
    "            # ---------- Validation ----------\n",
    "            # Make sure the model is in eval mode so that some modules like dropout are disabled and work normally.\n",
    "            model.eval()\n",
    "            # These are used to record information in validation.\n",
    "            valid_loss = []\n",
    "            valid_accs = []\n",
    "\n",
    "            # Iterate the validation set by batches.\n",
    "            for batch in tqdm(valid_loader):\n",
    "                # A batch consists of image data and corresponding labels.\n",
    "                imgs, labels, data_file = batch\n",
    "                # We don't need gradient in validation.\n",
    "                # Using torch.no_grad() accelerates the forward process.\n",
    "                with torch.no_grad():\n",
    "                    logits = model(imgs.to(device))\n",
    "                # We can still compute the loss (but not the gradient).\n",
    "                loss = criterion(logits, labels.to(device))\n",
    "                # Compute the accuracy for current batch.\n",
    "                acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n",
    "                # Record the loss and accuracy.\n",
    "                valid_loss.append(loss.item())\n",
    "                valid_accs.append(acc.item())\n",
    "\n",
    "            # The average loss and accuracy for entire validation set is the average of the recorded values.\n",
    "            valid_loss = sum(valid_loss) / len(valid_loss)\n",
    "            valid_acc = sum(valid_accs) / len(valid_accs)\n",
    "\n",
    "            record['loss']['valid'].append(valid_loss)\n",
    "            record['acc']['valid'].append(valid_acc)\n",
    "\n",
    "            # Print the information.\n",
    "            print(f\"[ Valid | {epoch + 1:04d}/{n_epochs:04d} ] loss = {valid_loss:.6f}, acc = {valid_acc:.6f}\")\n",
    "\n",
    "            # if the model improves, save a checkpoint at this epoch\n",
    "            if valid_acc > best_acc:\n",
    "                best_acc = valid_acc\n",
    "                torch.save(model.state_dict(), config['model_path'])\n",
    "                print(f'[Info] Saving model with Train Acc: {train_acc:.6f} | val acc: {valid_acc:.6f}')\n",
    "            \n",
    "            scheduler.step(valid_loss)\n",
    "        else:\n",
    "            # If you don't have validation set, simply save the model with the highest training accuracy \n",
    "            if train_acc > best_acc:\n",
    "                best_acc = train_acc\n",
    "                torch.save(model.state_dict(), config['model_path'])\n",
    "                print(f'[Info] Saving model with Train Acc: {train_acc:.6f}')\n",
    "                \n",
    "            scheduler.step(train_loss)\n",
    "        \n",
    "        curr_lr = optimizer.param_groups[0]['lr']\n",
    "        if curr_lr != lr:\n",
    "            print(f'[Info] Current learning rate: {curr_lr:.8f}')\n",
    "            lr = curr_lr\n",
    "            \n",
    "    print('Best Acc:', str(best_acc)[:7])\n",
    "    print('Learning rate:', lr)\n",
    "    return record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f540ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix seeds and device\n",
    "config = set_config()\n",
    "same_seeds(config['seed'])\n",
    "\n",
    "# \"cuda\" only when GPUs are available.\n",
    "device = get_device()\n",
    "model = CNN().to(device)\n",
    "\n",
    "# Print model\n",
    "summary(model, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d1555e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['num_epoch'] = 1\n",
    "config['num_workers'] = 0\n",
    "config['batch_size'] = 256\n",
    "record = Train(config=config, train_set=data.train_dataset, valid_set=data.valid_dataset, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d74594",
   "metadata": {},
   "source": [
    "## Plot Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b5af6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(record, y_lim, y_label='', title=''):\n",
    "    ''' Plot learning curve of your CNN (train & valid loss) '''\n",
    "    figure(figsize=(6, 4))\n",
    "    x_1 = list(range(len(record['train'])))\n",
    "    plt.plot(x_1, record['train'], c='tab:red', label='train')\n",
    "    if record['valid']:\n",
    "        x_2 = list(range(len(record['valid'])))\n",
    "        plt.plot(x_2, record['valid'], c='tab:cyan', label='valid')\n",
    "    plt.ylim(0.0, y_lim)\n",
    "    plt.xlabel('training steps')\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title('Learning curve {}'.format(title))\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ca1cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(record['loss'], y_lim=3.0, y_label='Loss')\n",
    "plot_learning_curve(record['acc'], y_lim=1.0, y_label='Acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d3992a",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91e0737",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(loader_valid, model):\n",
    "    # switch to eval mode\n",
    "    model.eval()\n",
    "    # These are used to record information in validation.\n",
    "    valid_accs = []\n",
    "    valid_labels = []\n",
    "    valid_prediction = []\n",
    "\n",
    "    # Iterate the validation set by batches.\n",
    "    for batch in tqdm(loader_valid):\n",
    "        # A batch consists of image data and corresponding labels.\n",
    "        imgs, labels, data_file = batch\n",
    "        # We don't need gradient in validation.\n",
    "        # Using torch.no_grad() accelerates the forward process.\n",
    "        with torch.no_grad():\n",
    "            logits = model(imgs.to(device))\n",
    "\n",
    "        # Compute the accuracy for current batch.\n",
    "        pred = logits.argmax(dim=-1)\n",
    "        acc = (pred == labels.to(device)).float().mean()\n",
    "        valid_labels.extend(labels)\n",
    "        valid_prediction.extend(pred.cpu())\n",
    "        # Record the loss and accuracy.\n",
    "        valid_accs.append(acc.item())\n",
    "\n",
    "    # The average loss and accuracy for entire validation set is the average of the recorded values.\n",
    "    valid_acc = sum(valid_accs) / len(valid_accs)\n",
    "\n",
    "    # Print the information.\n",
    "    print(f\"[ Valid ] acc = {valid_acc:.6f}\")\n",
    "\n",
    "    return valid_labels, valid_prediction\n",
    "\n",
    "loader_valid = DataLoader(data.valid_dataset, batch_size=config['batch_size'], shuffle=False, \n",
    "                                  pin_memory=True, num_workers=config['num_workers'])\n",
    "valid_labels, valid_prediction = validation(loader_valid, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13b81e9",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13415a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# define function\n",
    "def plot_confusion_matrix(cm):\n",
    "    ncm = []\n",
    "    title = 'Confusion Matrix'\n",
    "    df_cm = pd.DataFrame(cm, range(10), range(10))\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    sns.set(font_scale=1.5) \n",
    "    sns.heatmap(df_cm, annot=True, linewidths=0, annot_kws={\"size\": 12}, cmap=\"Blues\", fmt='g')\n",
    "    plt.xlabel('predict') # 橫軸是 prediction\n",
    "    plt.ylabel('truth')   # 縱軸是 truth\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# TODO: Use confusion_matrix & plot_confusion_matrix \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c508d45",
   "metadata": {},
   "source": [
    "## Testing / Making prediction file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd20f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(loader_test, model, output_file_name='prediction.csv'):\n",
    "    outputs = []\n",
    "    datafiles = []\n",
    "\n",
    "    # switch to eval mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, targets, datafile) in enumerate(loader_test, 1):\n",
    "            \n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            preds = model(inputs)\n",
    "            _, output = preds.topk(1, 1, True, True)\n",
    "            outputs.extend(list(output.reshape(-1).cpu().detach().numpy()))\n",
    "            datafiles.extend(list(datafile))\n",
    "\n",
    "    output_file = dict()\n",
    "    output_file['image_name'] = datafiles\n",
    "    output_file['label'] = outputs\n",
    "    \n",
    "    output_file = pd.DataFrame.from_dict(output_file)\n",
    "    output_file.to_csv(output_file_name, index = False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55923b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_test = DataLoader(data.test_dataset, batch_size=config['batch_size'], shuffle=False, \n",
    "                                  pin_memory=True, num_workers=config['num_workers'])\n",
    "inference(loader_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a133a676",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
